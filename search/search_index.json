{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"VisualAlgo VisualAlgo is a collection of algorithms and models intersecting the domains of computer vision and neuroscience. The repository is categorized based on the major tasks/stages in visual processing. Each category includes relevant algorithms from both computer vision and neuroscience. Disclaimer This repository is created purely for educational purposes. It contains implementations of algorithms that might be copyrighted or protected by other legal means. The goal is to showcase these implementations as a personal project and to facilitate learning. Please note that while you are welcome to browse and learn from this code, I highly discourage using it directly in any production system or for any commercial purposes, as it may infringe upon the rights of the original algorithm authors or patent holders. For each algorithm implemented, aside from those widely used and commonly known, I have included citations and references to the original papers where they were presented. Always be sure to respect the rights of the original creators and acknowledge their work. It is your responsibility to ensure that you have the proper legal permission to use any code or concept presented here. This code is provided \"as is\" and without any warranties. The author of this repository is not responsible for any consequences that may arise from your use of the code. Please also note that this repository is currently a work in progress and may contain bugs.","title":"Home"},{"location":"#visualalgo","text":"VisualAlgo is a collection of algorithms and models intersecting the domains of computer vision and neuroscience. The repository is categorized based on the major tasks/stages in visual processing. Each category includes relevant algorithms from both computer vision and neuroscience.","title":"VisualAlgo"},{"location":"#disclaimer","text":"This repository is created purely for educational purposes. It contains implementations of algorithms that might be copyrighted or protected by other legal means. The goal is to showcase these implementations as a personal project and to facilitate learning. Please note that while you are welcome to browse and learn from this code, I highly discourage using it directly in any production system or for any commercial purposes, as it may infringe upon the rights of the original algorithm authors or patent holders. For each algorithm implemented, aside from those widely used and commonly known, I have included citations and references to the original papers where they were presented. Always be sure to respect the rights of the original creators and acknowledge their work. It is your responsibility to ensure that you have the proper legal permission to use any code or concept presented here. This code is provided \"as is\" and without any warranties. The author of this repository is not responsible for any consequences that may arise from your use of the code. Please also note that this repository is currently a work in progress and may contain bugs.","title":"Disclaimer"},{"location":"pages/attention-and-search/","text":"8. Attention and Search Computer Vision Algorithms Selective Search Neuroscience Models Feature Integration Theory Biased Competition Model","title":"8. Attention and Search"},{"location":"pages/attention-and-search/#8-attention-and-search","text":"","title":"8. Attention and Search"},{"location":"pages/attention-and-search/#computer-vision-algorithms","text":"Selective Search","title":"Computer Vision Algorithms"},{"location":"pages/attention-and-search/#neuroscience-models","text":"Feature Integration Theory Biased Competition Model","title":"Neuroscience Models"},{"location":"pages/color-vision/","text":"7. Color Vision Computer Vision Algorithms Gamma Compression Neuroscience Models Opponent Process Models Retinex Theory","title":"7. Color Vision"},{"location":"pages/color-vision/#7-color-vision","text":"","title":"7. Color Vision"},{"location":"pages/color-vision/#computer-vision-algorithms","text":"Gamma Compression","title":"Computer Vision Algorithms"},{"location":"pages/color-vision/#neuroscience-models","text":"Opponent Process Models Retinex Theory","title":"Neuroscience Models"},{"location":"pages/depth-perception-and-3d-reconstruction/","text":"6. Depth Perception and 3D Reconstruction Computer Vision Algorithms Stereo Vision Struction from Motion (SfM), SLAM Image Stiching Neuroscience Models Binocular Disparity Models Motion Parallax Models","title":"6. Depth Perception and 3D Reconstruction"},{"location":"pages/depth-perception-and-3d-reconstruction/#6-depth-perception-and-3d-reconstruction","text":"","title":"6. Depth Perception and 3D Reconstruction"},{"location":"pages/depth-perception-and-3d-reconstruction/#computer-vision-algorithms","text":"Stereo Vision Struction from Motion (SfM), SLAM Image Stiching","title":"Computer Vision Algorithms"},{"location":"pages/depth-perception-and-3d-reconstruction/#neuroscience-models","text":"Binocular Disparity Models Motion Parallax Models","title":"Neuroscience Models"},{"location":"pages/feature-extraction/","text":"2. Feature Extraction Computer Vision Algorithms Sobel Filters ( VisualAlgo::FeatureExtraction::Gradients ) The Gradients class in the VisualAlgo::FeatureExtraction namespace is a utility class for computing the x and y gradients of an image, which are important components in various computer vision and image processing tasks such as edge detection and feature extraction. Include #include \"FeatureExtraction/Gradients.hpp\" Static Functions Matrix computeXGradient(const Matrix& image) : This static function takes an input image in the form of a Matrix and computes the x-direction gradients of the image. This operation typically involves convolving the image with a kernel (e.g., the Sobel operator in the x-direction) that detects changes in intensity in the x-direction. The output is a Matrix of the same size as the input image, where each element represents the x-direction gradient at the corresponding pixel in the input image. Matrix computeYGradient(const Matrix& image) : This static function works similar to computeXGradient , but it computes the gradients in the y-direction. The output is a Matrix of the same size as the input image, where each element represents the y-direction gradient at the corresponding pixel in the input image. Example Usage In this example, the Gradients class is used to compute the x and y gradients of an image. These gradients are then saved to file and compared with the expected gradients to ensure the computations are correct. VisualAlgo::Matrix image; image.load(\"datasets/FeatureExtraction/cat_resized.ppm\"); image.normalize(); VisualAlgo::Matrix image_x_gradient, image_y_gradient; image_x_gradient = VisualAlgo::FeatureExtraction::Gradients::computeXGradient(image); image_y_gradient = VisualAlgo::FeatureExtraction::Gradients::computeYGradient(image); image_x_gradient.save(\"datasets/FeatureExtraction/cat_x_gradient.ppm\", true); image_y_gradient.save(\"datasets/FeatureExtraction/cat_y_gradient.ppm\", true); In this code, computeXGradient and computeYGradient are used to calculate the x and y gradients of the loaded image respectively. The resulting gradient images are then saved to file for later analysis or visualization. Canny Edge Detection Corner Detection Blob Detection SIFT SURF ORB HOG Neuroscience Models Simple and Complex Cell Models","title":"2. Feature Extraction"},{"location":"pages/feature-extraction/#2-feature-extraction","text":"","title":"2. Feature Extraction"},{"location":"pages/feature-extraction/#computer-vision-algorithms","text":"","title":"Computer Vision Algorithms"},{"location":"pages/feature-extraction/#sobel-filters-visualalgofeatureextractiongradients","text":"The Gradients class in the VisualAlgo::FeatureExtraction namespace is a utility class for computing the x and y gradients of an image, which are important components in various computer vision and image processing tasks such as edge detection and feature extraction.","title":"Sobel Filters (VisualAlgo::FeatureExtraction::Gradients)"},{"location":"pages/feature-extraction/#include","text":"#include \"FeatureExtraction/Gradients.hpp\"","title":"Include"},{"location":"pages/feature-extraction/#static-functions","text":"Matrix computeXGradient(const Matrix& image) : This static function takes an input image in the form of a Matrix and computes the x-direction gradients of the image. This operation typically involves convolving the image with a kernel (e.g., the Sobel operator in the x-direction) that detects changes in intensity in the x-direction. The output is a Matrix of the same size as the input image, where each element represents the x-direction gradient at the corresponding pixel in the input image. Matrix computeYGradient(const Matrix& image) : This static function works similar to computeXGradient , but it computes the gradients in the y-direction. The output is a Matrix of the same size as the input image, where each element represents the y-direction gradient at the corresponding pixel in the input image.","title":"Static Functions"},{"location":"pages/feature-extraction/#example-usage","text":"In this example, the Gradients class is used to compute the x and y gradients of an image. These gradients are then saved to file and compared with the expected gradients to ensure the computations are correct. VisualAlgo::Matrix image; image.load(\"datasets/FeatureExtraction/cat_resized.ppm\"); image.normalize(); VisualAlgo::Matrix image_x_gradient, image_y_gradient; image_x_gradient = VisualAlgo::FeatureExtraction::Gradients::computeXGradient(image); image_y_gradient = VisualAlgo::FeatureExtraction::Gradients::computeYGradient(image); image_x_gradient.save(\"datasets/FeatureExtraction/cat_x_gradient.ppm\", true); image_y_gradient.save(\"datasets/FeatureExtraction/cat_y_gradient.ppm\", true); In this code, computeXGradient and computeYGradient are used to calculate the x and y gradients of the loaded image respectively. The resulting gradient images are then saved to file for later analysis or visualization.","title":"Example Usage"},{"location":"pages/feature-extraction/#canny-edge-detection","text":"","title":"Canny Edge Detection"},{"location":"pages/feature-extraction/#corner-detection","text":"","title":"Corner Detection"},{"location":"pages/feature-extraction/#blob-detection","text":"","title":"Blob Detection"},{"location":"pages/feature-extraction/#sift","text":"","title":"SIFT"},{"location":"pages/feature-extraction/#surf","text":"","title":"SURF"},{"location":"pages/feature-extraction/#orb","text":"","title":"ORB"},{"location":"pages/feature-extraction/#hog","text":"","title":"HOG"},{"location":"pages/feature-extraction/#neuroscience-models","text":"","title":"Neuroscience Models"},{"location":"pages/feature-extraction/#simple-and-complex-cell-models","text":"","title":"Simple and Complex Cell Models"},{"location":"pages/getting-started/","text":"Getting Started","title":"Getting Started"},{"location":"pages/getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"pages/image-processing-and-enhancement/","text":"1. Image Pre-processing and Enhancement Computer Vision Algorithms Histogram Equalization Neuroscience Models Center-Surround Model","title":"1. Image Processing and Enhancement"},{"location":"pages/image-processing-and-enhancement/#1-image-pre-processing-and-enhancement","text":"","title":"1. Image Pre-processing and Enhancement"},{"location":"pages/image-processing-and-enhancement/#computer-vision-algorithms","text":"Histogram Equalization","title":"Computer Vision Algorithms"},{"location":"pages/image-processing-and-enhancement/#neuroscience-models","text":"Center-Surround Model","title":"Neuroscience Models"},{"location":"pages/learning-and-memory/","text":"9. Learning and Memory Computer Vision Algorithms Deep Learning Models (CNN, Autoencoders, GAN, Transformers) Neuroscience Models Hopfield Network Adaptive Resonance Theory (ART)","title":"9. Learning and Memory"},{"location":"pages/learning-and-memory/#9-learning-and-memory","text":"","title":"9. Learning and Memory"},{"location":"pages/learning-and-memory/#computer-vision-algorithms","text":"Deep Learning Models (CNN, Autoencoders, GAN, Transformers)","title":"Computer Vision Algorithms"},{"location":"pages/learning-and-memory/#neuroscience-models","text":"Hopfield Network Adaptive Resonance Theory (ART)","title":"Neuroscience Models"},{"location":"pages/matrix/","text":"VisualAlgo::Matrix Struct Documentation The Matrix struct provides a two-dimensional matrix object, along with numerous methods for performing operations on the matrix. Include #include \"helpers/matrix.hpp\" Struct Attributes rows ( int ): The number of rows in the matrix. cols ( int ): The number of columns in the matrix. data ( vector<vector<float>> ): A 2D vector that holds the matrix data. Constructors Matrix(int rows, int cols) : Constructs a new Matrix object with the given number of rows and columns. The matrix is initialized with all elements set to 0. VisualAlgo::Matrix m(3, 4); // Creates a 3x4 matrix with all elements initialized to 0 Matrix(int rows, int cols, float value) : Constructs a new Matrix object with the given number of rows and columns. The matrix is initialized with all elements set to the provided value. VisualAlgo::Matrix m(3, 4, 1.0); // Creates a 3x4 matrix with all elements initialized to 1.0 Matrix(vector<vector<float>> data) : Constructs a new Matrix object with the provided 2D vector data. std::vector<std::vector<float>> data = {{1.0, 2.0, 3.0}, {4.0, 5.0, 6.0}}; VisualAlgo::Matrix m(data); // Creates a 2x3 matrix with the provided data or VisualAlgo::Matrix m({{1.0, 2.0, 3.0}, {4.0, 5.0, 6.0}}); Matrix(const Matrix &other) : Copy constructor. Constructs a new Matrix object that is a copy of the provided matrix. VisualAlgo::Matrix m1(3, 4, 1.0); VisualAlgo::Matrix m2(m1); // Creates a new matrix that is a copy of m1 Special Matrix Constructors Matrix::zeros(int rows, int cols) : Returns a new Matrix object with the specified number of rows and columns. All elements of the matrix are initialized to 0. VisualAlgo::Matrix m = VisualAlgo::Matrix::zeros(3, 4); // Creates a 3x4 matrix with all elements initialized to 0 Matrix::ones(int rows, int cols) : Returns a new Matrix object with the specified number of rows and columns. All elements of the matrix are initialized to 1. VisualAlgo::Matrix m = VisualAlgo::Matrix::ones(3, 4); // Creates a 3x4 matrix with all elements initialized to 1 Matrix::eye(int rows, int cols) : Returns a new identity Matrix object with the specified number of rows and columns. All diagonal elements are set to 1, and all other elements are set to 0. VisualAlgo::Matrix m = VisualAlgo::Matrix::eye(3, 3); // Creates a 3x3 identity matrix Random Matrix Constructors Matrix::random(int rows, int cols) : Returns a new Matrix object with the specified number of rows and columns. All elements of the matrix are initialized to a random floating point value in the range [0, 1]. VisualAlgo::Matrix m = VisualAlgo::Matrix::random(3, 4); // Creates a 3x4 matrix with all elements initialized to a random value Matrix::random(int rows, int cols, float min, float max) : Returns a new Matrix object with the specified number of rows and columns. All elements of the matrix are initialized to a random floating point value in the range [min, max]. VisualAlgo::Matrix m = VisualAlgo::Matrix::random(3, 4, -1.0, 1.0); // Creates a 3x4 matrix with all elements initialized to a random value between -1.0 and 1.0 Element-wise Operations Element-wise operations perform the operation on each element of the matrix independently. Matrix &operator=(const Matrix &other) : Assignment operator. Copies the provided matrix to the current matrix. VisualAlgo::Matrix m1(3, 4, 1.0); VisualAlgo::Matrix m2 = m1; // m2 is now a copy of m1 Matrix operator+(const Matrix &other) : Adds the provided matrix to the current matrix. VisualAlgo::Matrix m1(2, 2, 1.0); VisualAlgo::Matrix m2(2, 2, 2.0); VisualAlgo::Matrix m3 = m1 + m2; // m3 is now a 2x2 matrix with all elements set to 3.0 Matrix operator+(const float &other) : Add the provided float to all entries. Also support other common arithmetic operators. Element-wise Comparison Functions Matrix::elementwise_max(const Matrix &a, const Matrix &b) : Returns a new Matrix that is the element-wise maximum of matrices a and b . The dimensions of a and b must be the same. VisualAlgo::Matrix a = VisualAlgo::Matrix::ones(3, 4); VisualAlgo::Matrix b = VisualAlgo::Matrix::zeros(3, 4); VisualAlgo::Matrix m = VisualAlgo::Matrix::elementwise_max(a, b); // m will be a 3x4 matrix with all elements equal to 1 Matrix::elementwise_min(const Matrix &a, const Matrix &b) : Returns a new Matrix that is the element-wise minimum of matrices a and b . The dimensions of a and b must be the same. VisualAlgo::Matrix a = VisualAlgo::Matrix::ones(3, 4); VisualAlgo::Matrix b = VisualAlgo::Matrix::zeros(3, 4); VisualAlgo::Matrix m = VisualAlgo::Matrix::elementwise_min(a, b); // m will be a 3x4 matrix with all elements equal to 0 The Matrix struct supports a variety of comparison operations for comparing two Matrix objects or a Matrix object with a float. bool operator==(const Matrix &other) const : Compares the current matrix with other for equality. Returns true if all elements in the two matrices are exactly equal, and false otherwise. Matrix m1({{1, 2, 3}, {4, 5, 6}}); Matrix m2({{1, 2, 3}, {4, 5, 6}}); bool isEqual = (m1 == m2); // Returns true bool operator!=(const Matrix &other) const : Compares the current matrix with other for inequality. Returns true if any element in the two matrices is not equal, and false otherwise. Matrix m1({{1, 2, 3}, {4, 5, 6}}); Matrix m2({{1, 2, 3}, {7, 8, 9}}); bool isNotEqual = (m1 != m2); // Returns true bool is_close(const Matrix &other, float tolerance=1e-5) const : Compares the current matrix with other within a given tolerance . Returns true if the absolute difference between each corresponding pair of elements in the two matrices is less than or equal to the tolerance , and false otherwise. Matrix m1({{1.0, 2.0, 3.0}, {4.0, 5.0, 6.0}}); Matrix m2({{1.00001, 2.00001, 3.00001}, {3.99999, 5.00001, 5.99999}}); bool isClose = m1.is_close(m2); // Returns true Matrix operator>(const Matrix &other) const : Returns a binary matrix with 1 s where the corresponding element in the current matrix is greater than that in other , and 0 s elsewhere. Matrix m1({{1, 2, 3}, {4, 5, 6}}); Matrix m2({{-1, 2, 4}, {-99, 55, 0}}); Matrix m3 = m1 > m2; // Returns a binary matrix Matrix operator<(const Matrix &other) const : Similar to the > operator, but checks for less than. Matrix operator>=(const Matrix &other) const : Similar to the > operator, but checks for greater than or equal to. Matrix operator<=(const Matrix &other) const : Similar to the > operator, but checks for less than or equal to. In addition to the matrix-matrix comparison operators, there are similar matrix-float comparison operators for comparing each element in a matrix to a float. These are operator>(const float &other) const , operator<(const float &other) const , operator>=(const float &other) const , and operator<=(const float &other) const . Matrix m1({{1, 2, 3}, {4, 5, 6}}); Matrix m2 = m1 > 3; // Returns a binary matrix with `1`s where the elements in m1 are greater than 3 and `0`s elsewhere Matrix Operations Matrix transpose() : Returns the transpose of the current matrix. VisualAlgo::Matrix m1(2, 3, 1.0); VisualAlgo::Matrix m2 = m1.transpose(); // m2 is now a 3x2 matrix float dot(const Matrix &other) : Calculates the dot product of the current matrix with the provided matrix. VisualAlgo::Matrix m1(3, 3, 1.0); VisualAlgo::Matrix m2(3, 3, 2.0); float result = m1.dot(m2); // result is now 18 Matrix Matrix::matmul(const Matrix &other) : Matrix multiplication. auto m1 = Matrix({{1, 2, 3}, {4, 5, 6}}); auto m2 = Matrix({{10, 11}, {20, 21}, {30, 31}}); auto m3 = m1.matmul(m2); Accessors void set(int row, int col, float value) : Sets the value at the specified row and column in the matrix. VisualAlgo::Matrix m(3, 4, 0.0); m.set(1, 2, 1.0); // Sets the value at row 1, column 2 to 1.0 const float get(int row, int col) const : Returns the value at the specified row and column in the matrix. VisualAlgo::Matrix m(3, 4, 1.0); float value = m.get(2, 3); // Gets the value at row 2, column 3 std::vector<float> &operator[](int row) : Returns the row at the specified index in the matrix. VisualAlgo::Matrix m(3, 4, 1.0); std::vector<float> row = m[1]; // Gets the second row of the matrix Statistics float sum() : Returns the sum of all elements in the matrix. VisualAlgo::Matrix m(2, 3, 1.0); float sum = m.sum(); // sum is now 6.0 float mean() : Returns the mean (average) of all elements in the matrix. VisualAlgo::Matrix m(2, 3, 1.0); float mean = m.mean(); // mean is now 1.0 Also supports std() , max() , and min() operations. Image Operations void Matrix::load(const std::string &filename) : This function loads an image from the specified file path and stores it as a grayscale matrix. The function can only handle images in PPM format (P6). If the file doesn't exist or the file format is not P6, it will throw a runtime error. VisualAlgo::Matrix m; m.load(\"path_to_your_image.ppm\"); // Loads the image from the specified path This function reads the image file as a binary file. It first reads the header to ensure that the image is in the correct format (P6), then reads the width and height of the image. The pixel data is then read and converted from RGB to grayscale using the ITU-R BT.709 luma transform. The grayscale pixel values are stored in the data member of the Matrix object. Matrix Matrix::load(const std::string &filename, int rows, int cols) : Directly load an image. VisualAlgo::Matrix m = VisualAlgo::Matrix.load(\"path_to_your_image.ppm\", 256, 256); void Matrix::save(const std::string &filename, bool normalize) const : This function saves the matrix as an image to the specified file path. The image is saved in PPM format (P6). The normalize parameter specifies whether the matrix data should be normalized to the range 0-255 before saving. If not normalized and the pixel values are not within this range, a runtime error is thrown. VisualAlgo::Matrix m(3, 4, 1.0); m.save(\"path_to_save_image.ppm\", true); // Normalizes and saves the matrix as an image to the specified path This function first checks if the data needs normalization based on the normalize flag. If true, it normalizes the data in the Matrix object to the range 0-255 using the normalize255() function. Then it writes the image data to the file in PPM format (P6). The pixel data is written as RGB, where the R, G, and B values are all equal, resulting in a grayscale image. void Matrix::normalize() : This function normalizes the values in the matrix to the range [0, 1]. VisualAlgo::Matrix m(3, 4, 1.0); m.normalize(); // Normalizes the matrix values to the range [0, 1.0] void Matrix::normalize255() : This function normalizes the values in the matrix to the range [0.0, 255.0]. This is useful to prepare the data for saving as an image, since pixel values in an image must be in this range. VisualAlgo::Matrix m(3, 4, 1.0); m.normalize255(); // Normalizes the matrix values to the range [0, 255.0] void Matrix::relu() : This function applies the ReLU (Rectified Linear Unit) operation to the matrix. It replaces all negative pixel values with zeros, effectively achieving half-wave rectification. VisualAlgo::Matrix m(3, 4, -1.0); m.relu(); // Changes all negative values to 0 void abs() : This function take the absolute value of all the entries. Matrix Matrix::cross_correlate(const VisualAlgo::Matrix &kernel, int padding, int stride) const : This function performs the cross-correlation operation between the matrix and the provided kernel. The padding and stride parameters control the operation. If the kernel size is larger than the matrix or the stride is less than or equal to zero, or padding is negative, it will throw an invalid_argument exception. VisualAlgo::Matrix m(3, 4, 1.0); VisualAlgo::Matrix kernel(2, 2, 0.5); VisualAlgo::Matrix result = m.cross_correlate(kernel, 1, 2); // Perform cross-correlation This function creates an output matrix of appropriate size based on the input matrix, kernel, padding, and stride. It then performs the cross-correlation operation and stores the result in the output matrix. Matrix Matrix::cross_correlate(const VisualAlgo::Matrix &kernel) const : This function performs cross-correlation on the matrix with the provided kernel. The output matrix is always the same size as the input matrix. This operation effectively considers there to be zero padding beyond the edges of the original matrix and will wrap around when indexing beyond its dimensions. Matrix Matrix::cross_correlate_full(const VisualAlgo::Matrix &kernel) const : This function performs cross-correlation operation on the matrix with the provided kernel, with zero padding. The output matrix size is larger than the input matrix size, taking into account the kernel size and the full overlap. Matrix Matrix::flip() const : This function returns a new matrix which is the flipped version of the current matrix. This is particularly useful when trying to perform convolution using a kernel, as convolution is mathematically the same as cross-correlation with a flipped kernel. Matrix Matrix::convolve(const VisualAlgo::Matrix &kernel, int padding, int stride) const : This function performs convolution between the matrix and the provided kernel. It first flips the kernel and then performs cross-correlation. The padding and stride parameters are similar to the cross-correlation function. Matrix Matrix::convolve(const VisualAlgo::Matrix &kernel) const : This function performs convolution on the matrix with the provided kernel and keeps the same size. This operation effectively considers there to be zero padding beyond the edges of the original matrix and will wrap around when indexing beyond its dimensions.","title":"Matrix"},{"location":"pages/matrix/#visualalgomatrix-struct-documentation","text":"The Matrix struct provides a two-dimensional matrix object, along with numerous methods for performing operations on the matrix.","title":"VisualAlgo::Matrix Struct Documentation"},{"location":"pages/matrix/#include","text":"#include \"helpers/matrix.hpp\"","title":"Include"},{"location":"pages/matrix/#struct-attributes","text":"rows ( int ): The number of rows in the matrix. cols ( int ): The number of columns in the matrix. data ( vector<vector<float>> ): A 2D vector that holds the matrix data.","title":"Struct Attributes"},{"location":"pages/matrix/#constructors","text":"Matrix(int rows, int cols) : Constructs a new Matrix object with the given number of rows and columns. The matrix is initialized with all elements set to 0. VisualAlgo::Matrix m(3, 4); // Creates a 3x4 matrix with all elements initialized to 0 Matrix(int rows, int cols, float value) : Constructs a new Matrix object with the given number of rows and columns. The matrix is initialized with all elements set to the provided value. VisualAlgo::Matrix m(3, 4, 1.0); // Creates a 3x4 matrix with all elements initialized to 1.0 Matrix(vector<vector<float>> data) : Constructs a new Matrix object with the provided 2D vector data. std::vector<std::vector<float>> data = {{1.0, 2.0, 3.0}, {4.0, 5.0, 6.0}}; VisualAlgo::Matrix m(data); // Creates a 2x3 matrix with the provided data or VisualAlgo::Matrix m({{1.0, 2.0, 3.0}, {4.0, 5.0, 6.0}}); Matrix(const Matrix &other) : Copy constructor. Constructs a new Matrix object that is a copy of the provided matrix. VisualAlgo::Matrix m1(3, 4, 1.0); VisualAlgo::Matrix m2(m1); // Creates a new matrix that is a copy of m1","title":"Constructors"},{"location":"pages/matrix/#special-matrix-constructors","text":"Matrix::zeros(int rows, int cols) : Returns a new Matrix object with the specified number of rows and columns. All elements of the matrix are initialized to 0. VisualAlgo::Matrix m = VisualAlgo::Matrix::zeros(3, 4); // Creates a 3x4 matrix with all elements initialized to 0 Matrix::ones(int rows, int cols) : Returns a new Matrix object with the specified number of rows and columns. All elements of the matrix are initialized to 1. VisualAlgo::Matrix m = VisualAlgo::Matrix::ones(3, 4); // Creates a 3x4 matrix with all elements initialized to 1 Matrix::eye(int rows, int cols) : Returns a new identity Matrix object with the specified number of rows and columns. All diagonal elements are set to 1, and all other elements are set to 0. VisualAlgo::Matrix m = VisualAlgo::Matrix::eye(3, 3); // Creates a 3x3 identity matrix","title":"Special Matrix Constructors"},{"location":"pages/matrix/#random-matrix-constructors","text":"Matrix::random(int rows, int cols) : Returns a new Matrix object with the specified number of rows and columns. All elements of the matrix are initialized to a random floating point value in the range [0, 1]. VisualAlgo::Matrix m = VisualAlgo::Matrix::random(3, 4); // Creates a 3x4 matrix with all elements initialized to a random value Matrix::random(int rows, int cols, float min, float max) : Returns a new Matrix object with the specified number of rows and columns. All elements of the matrix are initialized to a random floating point value in the range [min, max]. VisualAlgo::Matrix m = VisualAlgo::Matrix::random(3, 4, -1.0, 1.0); // Creates a 3x4 matrix with all elements initialized to a random value between -1.0 and 1.0","title":"Random Matrix Constructors"},{"location":"pages/matrix/#element-wise-operations","text":"Element-wise operations perform the operation on each element of the matrix independently. Matrix &operator=(const Matrix &other) : Assignment operator. Copies the provided matrix to the current matrix. VisualAlgo::Matrix m1(3, 4, 1.0); VisualAlgo::Matrix m2 = m1; // m2 is now a copy of m1 Matrix operator+(const Matrix &other) : Adds the provided matrix to the current matrix. VisualAlgo::Matrix m1(2, 2, 1.0); VisualAlgo::Matrix m2(2, 2, 2.0); VisualAlgo::Matrix m3 = m1 + m2; // m3 is now a 2x2 matrix with all elements set to 3.0 Matrix operator+(const float &other) : Add the provided float to all entries. Also support other common arithmetic operators.","title":"Element-wise Operations"},{"location":"pages/matrix/#element-wise-comparison-functions","text":"Matrix::elementwise_max(const Matrix &a, const Matrix &b) : Returns a new Matrix that is the element-wise maximum of matrices a and b . The dimensions of a and b must be the same. VisualAlgo::Matrix a = VisualAlgo::Matrix::ones(3, 4); VisualAlgo::Matrix b = VisualAlgo::Matrix::zeros(3, 4); VisualAlgo::Matrix m = VisualAlgo::Matrix::elementwise_max(a, b); // m will be a 3x4 matrix with all elements equal to 1 Matrix::elementwise_min(const Matrix &a, const Matrix &b) : Returns a new Matrix that is the element-wise minimum of matrices a and b . The dimensions of a and b must be the same. VisualAlgo::Matrix a = VisualAlgo::Matrix::ones(3, 4); VisualAlgo::Matrix b = VisualAlgo::Matrix::zeros(3, 4); VisualAlgo::Matrix m = VisualAlgo::Matrix::elementwise_min(a, b); // m will be a 3x4 matrix with all elements equal to 0 The Matrix struct supports a variety of comparison operations for comparing two Matrix objects or a Matrix object with a float. bool operator==(const Matrix &other) const : Compares the current matrix with other for equality. Returns true if all elements in the two matrices are exactly equal, and false otherwise. Matrix m1({{1, 2, 3}, {4, 5, 6}}); Matrix m2({{1, 2, 3}, {4, 5, 6}}); bool isEqual = (m1 == m2); // Returns true bool operator!=(const Matrix &other) const : Compares the current matrix with other for inequality. Returns true if any element in the two matrices is not equal, and false otherwise. Matrix m1({{1, 2, 3}, {4, 5, 6}}); Matrix m2({{1, 2, 3}, {7, 8, 9}}); bool isNotEqual = (m1 != m2); // Returns true bool is_close(const Matrix &other, float tolerance=1e-5) const : Compares the current matrix with other within a given tolerance . Returns true if the absolute difference between each corresponding pair of elements in the two matrices is less than or equal to the tolerance , and false otherwise. Matrix m1({{1.0, 2.0, 3.0}, {4.0, 5.0, 6.0}}); Matrix m2({{1.00001, 2.00001, 3.00001}, {3.99999, 5.00001, 5.99999}}); bool isClose = m1.is_close(m2); // Returns true Matrix operator>(const Matrix &other) const : Returns a binary matrix with 1 s where the corresponding element in the current matrix is greater than that in other , and 0 s elsewhere. Matrix m1({{1, 2, 3}, {4, 5, 6}}); Matrix m2({{-1, 2, 4}, {-99, 55, 0}}); Matrix m3 = m1 > m2; // Returns a binary matrix Matrix operator<(const Matrix &other) const : Similar to the > operator, but checks for less than. Matrix operator>=(const Matrix &other) const : Similar to the > operator, but checks for greater than or equal to. Matrix operator<=(const Matrix &other) const : Similar to the > operator, but checks for less than or equal to. In addition to the matrix-matrix comparison operators, there are similar matrix-float comparison operators for comparing each element in a matrix to a float. These are operator>(const float &other) const , operator<(const float &other) const , operator>=(const float &other) const , and operator<=(const float &other) const . Matrix m1({{1, 2, 3}, {4, 5, 6}}); Matrix m2 = m1 > 3; // Returns a binary matrix with `1`s where the elements in m1 are greater than 3 and `0`s elsewhere","title":"Element-wise Comparison Functions"},{"location":"pages/matrix/#matrix-operations","text":"Matrix transpose() : Returns the transpose of the current matrix. VisualAlgo::Matrix m1(2, 3, 1.0); VisualAlgo::Matrix m2 = m1.transpose(); // m2 is now a 3x2 matrix float dot(const Matrix &other) : Calculates the dot product of the current matrix with the provided matrix. VisualAlgo::Matrix m1(3, 3, 1.0); VisualAlgo::Matrix m2(3, 3, 2.0); float result = m1.dot(m2); // result is now 18 Matrix Matrix::matmul(const Matrix &other) : Matrix multiplication. auto m1 = Matrix({{1, 2, 3}, {4, 5, 6}}); auto m2 = Matrix({{10, 11}, {20, 21}, {30, 31}}); auto m3 = m1.matmul(m2);","title":"Matrix Operations"},{"location":"pages/matrix/#accessors","text":"void set(int row, int col, float value) : Sets the value at the specified row and column in the matrix. VisualAlgo::Matrix m(3, 4, 0.0); m.set(1, 2, 1.0); // Sets the value at row 1, column 2 to 1.0 const float get(int row, int col) const : Returns the value at the specified row and column in the matrix. VisualAlgo::Matrix m(3, 4, 1.0); float value = m.get(2, 3); // Gets the value at row 2, column 3 std::vector<float> &operator[](int row) : Returns the row at the specified index in the matrix. VisualAlgo::Matrix m(3, 4, 1.0); std::vector<float> row = m[1]; // Gets the second row of the matrix","title":"Accessors"},{"location":"pages/matrix/#statistics","text":"float sum() : Returns the sum of all elements in the matrix. VisualAlgo::Matrix m(2, 3, 1.0); float sum = m.sum(); // sum is now 6.0 float mean() : Returns the mean (average) of all elements in the matrix. VisualAlgo::Matrix m(2, 3, 1.0); float mean = m.mean(); // mean is now 1.0 Also supports std() , max() , and min() operations.","title":"Statistics"},{"location":"pages/matrix/#image-operations","text":"void Matrix::load(const std::string &filename) : This function loads an image from the specified file path and stores it as a grayscale matrix. The function can only handle images in PPM format (P6). If the file doesn't exist or the file format is not P6, it will throw a runtime error. VisualAlgo::Matrix m; m.load(\"path_to_your_image.ppm\"); // Loads the image from the specified path This function reads the image file as a binary file. It first reads the header to ensure that the image is in the correct format (P6), then reads the width and height of the image. The pixel data is then read and converted from RGB to grayscale using the ITU-R BT.709 luma transform. The grayscale pixel values are stored in the data member of the Matrix object. Matrix Matrix::load(const std::string &filename, int rows, int cols) : Directly load an image. VisualAlgo::Matrix m = VisualAlgo::Matrix.load(\"path_to_your_image.ppm\", 256, 256); void Matrix::save(const std::string &filename, bool normalize) const : This function saves the matrix as an image to the specified file path. The image is saved in PPM format (P6). The normalize parameter specifies whether the matrix data should be normalized to the range 0-255 before saving. If not normalized and the pixel values are not within this range, a runtime error is thrown. VisualAlgo::Matrix m(3, 4, 1.0); m.save(\"path_to_save_image.ppm\", true); // Normalizes and saves the matrix as an image to the specified path This function first checks if the data needs normalization based on the normalize flag. If true, it normalizes the data in the Matrix object to the range 0-255 using the normalize255() function. Then it writes the image data to the file in PPM format (P6). The pixel data is written as RGB, where the R, G, and B values are all equal, resulting in a grayscale image. void Matrix::normalize() : This function normalizes the values in the matrix to the range [0, 1]. VisualAlgo::Matrix m(3, 4, 1.0); m.normalize(); // Normalizes the matrix values to the range [0, 1.0] void Matrix::normalize255() : This function normalizes the values in the matrix to the range [0.0, 255.0]. This is useful to prepare the data for saving as an image, since pixel values in an image must be in this range. VisualAlgo::Matrix m(3, 4, 1.0); m.normalize255(); // Normalizes the matrix values to the range [0, 255.0] void Matrix::relu() : This function applies the ReLU (Rectified Linear Unit) operation to the matrix. It replaces all negative pixel values with zeros, effectively achieving half-wave rectification. VisualAlgo::Matrix m(3, 4, -1.0); m.relu(); // Changes all negative values to 0 void abs() : This function take the absolute value of all the entries. Matrix Matrix::cross_correlate(const VisualAlgo::Matrix &kernel, int padding, int stride) const : This function performs the cross-correlation operation between the matrix and the provided kernel. The padding and stride parameters control the operation. If the kernel size is larger than the matrix or the stride is less than or equal to zero, or padding is negative, it will throw an invalid_argument exception. VisualAlgo::Matrix m(3, 4, 1.0); VisualAlgo::Matrix kernel(2, 2, 0.5); VisualAlgo::Matrix result = m.cross_correlate(kernel, 1, 2); // Perform cross-correlation This function creates an output matrix of appropriate size based on the input matrix, kernel, padding, and stride. It then performs the cross-correlation operation and stores the result in the output matrix. Matrix Matrix::cross_correlate(const VisualAlgo::Matrix &kernel) const : This function performs cross-correlation on the matrix with the provided kernel. The output matrix is always the same size as the input matrix. This operation effectively considers there to be zero padding beyond the edges of the original matrix and will wrap around when indexing beyond its dimensions. Matrix Matrix::cross_correlate_full(const VisualAlgo::Matrix &kernel) const : This function performs cross-correlation operation on the matrix with the provided kernel, with zero padding. The output matrix size is larger than the input matrix size, taking into account the kernel size and the full overlap. Matrix Matrix::flip() const : This function returns a new matrix which is the flipped version of the current matrix. This is particularly useful when trying to perform convolution using a kernel, as convolution is mathematically the same as cross-correlation with a flipped kernel. Matrix Matrix::convolve(const VisualAlgo::Matrix &kernel, int padding, int stride) const : This function performs convolution between the matrix and the provided kernel. It first flips the kernel and then performs cross-correlation. The padding and stride parameters are similar to the cross-correlation function. Matrix Matrix::convolve(const VisualAlgo::Matrix &kernel) const : This function performs convolution on the matrix with the provided kernel and keeps the same size. This operation effectively considers there to be zero padding beyond the edges of the original matrix and will wrap around when indexing beyond its dimensions.","title":"Image Operations"},{"location":"pages/motion-analysis-and-tracking/","text":"5. Motion Analysis and Tracking Computer Vision Algorithms Optical Flow Background Subtraction Kalman Filter CAMShift Neuroscience Models Reichardt Detectors Motion Energy Models","title":"5. Motion Analysis and Tracking"},{"location":"pages/motion-analysis-and-tracking/#5-motion-analysis-and-tracking","text":"","title":"5. Motion Analysis and Tracking"},{"location":"pages/motion-analysis-and-tracking/#computer-vision-algorithms","text":"Optical Flow Background Subtraction Kalman Filter CAMShift","title":"Computer Vision Algorithms"},{"location":"pages/motion-analysis-and-tracking/#neuroscience-models","text":"Reichardt Detectors Motion Energy Models","title":"Neuroscience Models"},{"location":"pages/object-detection-and-recognition/","text":"4. Object Detection and Recognition Computer Vision Algorithms Viola-Jones R-CNN SSD YOLO Haar Cascades Neuroscience Models HMAX Model","title":"4. Object Detection and Recognition"},{"location":"pages/object-detection-and-recognition/#4-object-detection-and-recognition","text":"","title":"4. Object Detection and Recognition"},{"location":"pages/object-detection-and-recognition/#computer-vision-algorithms","text":"Viola-Jones R-CNN SSD YOLO Haar Cascades","title":"Computer Vision Algorithms"},{"location":"pages/object-detection-and-recognition/#neuroscience-models","text":"HMAX Model","title":"Neuroscience Models"},{"location":"pages/segmentation-and-grouping/","text":"3. Segmentation and Grouping Computer Vision Algorithms Region Growing Watershed K-means Clustering Mean Shift GrabCut U-Net Region Proposal Network (RPN) Neuroscience Models The FBF Model Reference : Grossberg and Wyse, \"Figure-Ground Separation of Connected Scenic Figures: Boundaries, Filling-In, and Opponent Processing\", Neural Networks For Vision and Image Processing , Chapter 7, 1992. (Link to paper with the same topic but low scan quality) Overview : The FBF network model was used as part of the larger pattern recognition model by Grossberg et al.. It handles the initial steps of processing, up until the figure-ground separation phase. The FBF model is composed of two sub-systems: the Feature Contour System (FCS) and the Boundary Contour System (BCS), both initially proposed by Grossberg and Mingolla in 1985. As the processing sequence typically follows the pattern FCS-BCS-FCS, these combined systems are collectively referred to as the FBF networks. The central idea posited by Grossberg is that these two systems collaboratively enable us to recognize surfaces (handled by the FCS) and boundaries (handled by the BCS). The FCS's role is to fill in the entire boundary region with consistent surface characteristics, relying on the boundaries computed by the BCS, which connects collinear contours to establish these boundaries. A notable point raised by Grossberg is our ability to recognize boundaries even when they're not directly visible, leading to illusions such as the Kanizsa triangle. Please note that the FCS and BCS are hypothetical models for the visual system, distinguished by their function (\"what\" they are supposed to do) rather than their mechanism (\"how\" they are supposed to operate). These models have evolved significantly over time, and their definition is not bound by any specific method or implementation. The exact details often depend on specific research papers. Also, note that I've made a number of simplifications to the original model. For example, the original paper applied mathematics based on sub-pixel resolution (interpolating pixels), whereas the simple cells I used are entirely pixel-based. Algorithm Breakdown : The FBF model algorithm consists of four steps: Step 1: Discount the Illuminant : Instead of uniformly applying the ON-Center-OFF-Surround (ON-C) and OFF-Center-ON-Surround (OFF-C) kernels (also known as Difference of Gaussian), the kernel is scaled with the image value to handle areas with varying brightness levels. Grossberg describes these cells as \"shunting\" because their dynamics are dependent on their current state, akin to an electrical system with a (shunting) resistor. This is believed to be part of the FCS's work, as it needs to perceive surfaces as continuous over a broad range of illumination levels. The output of the ON-C and OFF-C processes are denoted as \\mathbf{x} and \\bar{\\mathbf{x}} respectively: \\mathbf{x} = \\frac{\\mathbf{I} \\otimes (B \\mathbf{C} - D \\mathbf{E})}{A + \\mathbf{I} \\otimes (\\mathbf{C} + \\mathbf{E})}\\\\ \\bar{\\mathbf{x}} = \\frac{A \\cdot S + \\mathbf{I} \\otimes (D \\mathbf{E} - B \\mathbf{C})}{A + \\mathbf{I} \\otimes (\\mathbf{C} + \\mathbf{E})} Here, the symbol \\otimes represents the operation of 2D cross-correlation. \\mathbf{I} represents the input image array, while A , B , and D are constants that define the shape of the ON-C and OFF-C kernels. The term S introduces the offset of the OFF-C kernel, ensuring that \\bar{\\mathbf{x}} primarily falls within the positive range. The values for those parameters can also be found in the paper. \\mathbf{C} and \\mathbf{E} denote two Gaussian kernels, as the ON-C and OFF-C kernels are \"Differences of Gaussians\" (DoG). The ON-C shape is derived from subtracting the wider and shorter Gaussian kernel \\mathbf{E} from the narrower and taller Gaussian kernel \\mathbf{C} . For the OFF-C kernel, the procedure is reversed. The formulas for these kernels are: \\mathbf{C} = C e^{-\\frac{(p - i)^2 + (q - j)^2}{\\alpha^2}}\\\\ \\mathbf{E} = E e^{-\\frac{(p - i)^2 + (q - j)^2}{\\beta^2}}\\\\ where \\alpha and \\beta are two other constants. (Interestingly, Grossberg and Wyse applied a logarithmic transformation to the arguments of the exponent in their paper, a step that I did not use in my implementation. Instead, I use the \"standard\" form of Gaussian shown above.) Step 2: CORT-X 2 Filter : The CORT-X 2 Filter is a neurophysiologically inspired model that draws on Hubel and Wiesel's work on Simple, Complex, and Hypercomplex cells. It forms the BCS part of this model. The filter takes the output from the previous step as its input, and generates the boundaries. It operates in a purely feedforward manner and can be broken down into six sub-steps: Step 2a: Simple Cells : These cells receive either \\mathbf{x} or \\bar{\\mathbf{x}} as inputs. The are two scales kernels s for the kernels: s=1 , with major and minor axes of 12 and 6 pixels, and s=2 , with major and minor axes of 20 and 10 pixels. The kernel, \\mathbf{K} , comprises two ellipse halves, \\mathbf{L_s} and \\mathbf{R_s} : \\mathbf{K}_{s, L} (k) = \\mathbf{L_s} (k) - \\alpha_s \\mathbf{R_s} (k) - \\beta_s \\mathbf{K}_{s, R} (k) = \\mathbf{R_s} (k) - \\alpha_s \\mathbf{L_s} (k) - \\beta_s Here, k denotes the orientation index of the kernel, ranging from k_0 = 0, k_1 = 22.5, ... to k_7 = 157.5 degrees. For clarity, note that Grossberg and Wyse didn't just rotate the simple cell kernel by 360 degrees. Instead, they rotate two kernels, \\mathbf{L_s} and \\mathbf{R_s} , with opposite polarities by 180 degrees. This is because the kernels of the same orientation and opposite polarity will combine in the next step, making this notation more intuitive. The output of the simple cells comes from the cross-correlation between the ON-C (or OFF-C) signals, followed by half-wave rectification: \\mathbf{S^+_{s, L}} (k) = \\max(\\mathbf{K}_{s, L} (k) \\otimes \\mathbf{x}, 0) \\mathbf{S^+_{s, R}} (k) = \\max(\\mathbf{K}_{s, R} (k) \\otimes \\mathbf{x}, 0) \\mathbf{S^-_{s, L}} (k) = \\max(\\mathbf{K}_{s, L} (k) \\otimes \\bar{\\mathbf{x}}, 0) \\mathbf{S^-_{s, R}} (k) = \\max(\\mathbf{K}_{s, R} (k) \\otimes \\bar{\\mathbf{x}}, 0) Step 2b: Complex Cells : The complex cells combine the responses from simple cells of the same orientation. Be aware that the \\mathbf{C} notation here represents the response map of complex cells, not the Gaussian from Step 1. \\mathbf{C}_s (k) = F \\left[ \\mathbf{S^+_{s, L}} (k) + \\mathbf{S^+_{s, R}} (k) + \\mathbf{S^-_{s, L}} (k) + \\mathbf{S^-_{s, R}} (k) \\right] Here, F is another constant parameter. Half-wave rectification isn't necessary as the output is always non-negative. Step 2c: Hypercomplex Cells (First Competitive Stage) : This step resembles the non-max suppression in Canny edge detection as it aims to inhibit texture around boundaries that lack other collinear edges. This is accomplished by dividing the complex cells response map by the cross-correlation between the complex cell response and the oriented competition kernel \\mathbf{G_s} (k) . This kernel is normalized and positive everywhere except along the direction of the complex cell's corresponding orientation. Consequently, if there are non-collinear edges in the vicinity, the cross-correlation term in the denominator becomes large. \\mathbf{D}_{s} (k) = \\max \\left[\\frac{\\mathbf{C_s}(k)}{\\epsilon + \\mu \\sum_m (\\mathbf{C_s} (m) \\otimes \\mathbf{G_s} (k))} - \\tau, 0\\right] Step 2d: Hypercomplex Cells (Second Competitive Stage) : In this stage, only the dominant orientation is preserved (winner-takes-all) for each location on the complex cell map, \\mathbf{C_s} (k) . \\mathbf{D}_s := \\max_k \\mathbf{D}_s (k) Step 2e: Multiple Scale Interaction: Boundary Localization and Noise Suppression : CONFIGR (Carpenter, Gaddam, and Mingolla, 2007) Paper Tolerance Space Theory (TST) for Gestalt Proximity Principle (Peng, Yang, and Li, 2021) Paper Gestalt Laws Models Border Ownership Models","title":"3. Segmentation and Grouping"},{"location":"pages/segmentation-and-grouping/#3-segmentation-and-grouping","text":"","title":"3. Segmentation and Grouping"},{"location":"pages/segmentation-and-grouping/#computer-vision-algorithms","text":"","title":"Computer Vision Algorithms"},{"location":"pages/segmentation-and-grouping/#region-growing","text":"","title":"Region Growing"},{"location":"pages/segmentation-and-grouping/#watershed","text":"","title":"Watershed"},{"location":"pages/segmentation-and-grouping/#k-means-clustering","text":"","title":"K-means Clustering"},{"location":"pages/segmentation-and-grouping/#mean-shift","text":"","title":"Mean Shift"},{"location":"pages/segmentation-and-grouping/#grabcut","text":"","title":"GrabCut"},{"location":"pages/segmentation-and-grouping/#u-net","text":"","title":"U-Net"},{"location":"pages/segmentation-and-grouping/#region-proposal-network-rpn","text":"","title":"Region Proposal Network (RPN)"},{"location":"pages/segmentation-and-grouping/#neuroscience-models","text":"","title":"Neuroscience Models"},{"location":"pages/segmentation-and-grouping/#the-fbf-model","text":"Reference : Grossberg and Wyse, \"Figure-Ground Separation of Connected Scenic Figures: Boundaries, Filling-In, and Opponent Processing\", Neural Networks For Vision and Image Processing , Chapter 7, 1992. (Link to paper with the same topic but low scan quality) Overview : The FBF network model was used as part of the larger pattern recognition model by Grossberg et al.. It handles the initial steps of processing, up until the figure-ground separation phase. The FBF model is composed of two sub-systems: the Feature Contour System (FCS) and the Boundary Contour System (BCS), both initially proposed by Grossberg and Mingolla in 1985. As the processing sequence typically follows the pattern FCS-BCS-FCS, these combined systems are collectively referred to as the FBF networks. The central idea posited by Grossberg is that these two systems collaboratively enable us to recognize surfaces (handled by the FCS) and boundaries (handled by the BCS). The FCS's role is to fill in the entire boundary region with consistent surface characteristics, relying on the boundaries computed by the BCS, which connects collinear contours to establish these boundaries. A notable point raised by Grossberg is our ability to recognize boundaries even when they're not directly visible, leading to illusions such as the Kanizsa triangle. Please note that the FCS and BCS are hypothetical models for the visual system, distinguished by their function (\"what\" they are supposed to do) rather than their mechanism (\"how\" they are supposed to operate). These models have evolved significantly over time, and their definition is not bound by any specific method or implementation. The exact details often depend on specific research papers. Also, note that I've made a number of simplifications to the original model. For example, the original paper applied mathematics based on sub-pixel resolution (interpolating pixels), whereas the simple cells I used are entirely pixel-based. Algorithm Breakdown : The FBF model algorithm consists of four steps: Step 1: Discount the Illuminant : Instead of uniformly applying the ON-Center-OFF-Surround (ON-C) and OFF-Center-ON-Surround (OFF-C) kernels (also known as Difference of Gaussian), the kernel is scaled with the image value to handle areas with varying brightness levels. Grossberg describes these cells as \"shunting\" because their dynamics are dependent on their current state, akin to an electrical system with a (shunting) resistor. This is believed to be part of the FCS's work, as it needs to perceive surfaces as continuous over a broad range of illumination levels. The output of the ON-C and OFF-C processes are denoted as \\mathbf{x} and \\bar{\\mathbf{x}} respectively: \\mathbf{x} = \\frac{\\mathbf{I} \\otimes (B \\mathbf{C} - D \\mathbf{E})}{A + \\mathbf{I} \\otimes (\\mathbf{C} + \\mathbf{E})}\\\\ \\bar{\\mathbf{x}} = \\frac{A \\cdot S + \\mathbf{I} \\otimes (D \\mathbf{E} - B \\mathbf{C})}{A + \\mathbf{I} \\otimes (\\mathbf{C} + \\mathbf{E})} Here, the symbol \\otimes represents the operation of 2D cross-correlation. \\mathbf{I} represents the input image array, while A , B , and D are constants that define the shape of the ON-C and OFF-C kernels. The term S introduces the offset of the OFF-C kernel, ensuring that \\bar{\\mathbf{x}} primarily falls within the positive range. The values for those parameters can also be found in the paper. \\mathbf{C} and \\mathbf{E} denote two Gaussian kernels, as the ON-C and OFF-C kernels are \"Differences of Gaussians\" (DoG). The ON-C shape is derived from subtracting the wider and shorter Gaussian kernel \\mathbf{E} from the narrower and taller Gaussian kernel \\mathbf{C} . For the OFF-C kernel, the procedure is reversed. The formulas for these kernels are: \\mathbf{C} = C e^{-\\frac{(p - i)^2 + (q - j)^2}{\\alpha^2}}\\\\ \\mathbf{E} = E e^{-\\frac{(p - i)^2 + (q - j)^2}{\\beta^2}}\\\\ where \\alpha and \\beta are two other constants. (Interestingly, Grossberg and Wyse applied a logarithmic transformation to the arguments of the exponent in their paper, a step that I did not use in my implementation. Instead, I use the \"standard\" form of Gaussian shown above.) Step 2: CORT-X 2 Filter : The CORT-X 2 Filter is a neurophysiologically inspired model that draws on Hubel and Wiesel's work on Simple, Complex, and Hypercomplex cells. It forms the BCS part of this model. The filter takes the output from the previous step as its input, and generates the boundaries. It operates in a purely feedforward manner and can be broken down into six sub-steps: Step 2a: Simple Cells : These cells receive either \\mathbf{x} or \\bar{\\mathbf{x}} as inputs. The are two scales kernels s for the kernels: s=1 , with major and minor axes of 12 and 6 pixels, and s=2 , with major and minor axes of 20 and 10 pixels. The kernel, \\mathbf{K} , comprises two ellipse halves, \\mathbf{L_s} and \\mathbf{R_s} : \\mathbf{K}_{s, L} (k) = \\mathbf{L_s} (k) - \\alpha_s \\mathbf{R_s} (k) - \\beta_s \\mathbf{K}_{s, R} (k) = \\mathbf{R_s} (k) - \\alpha_s \\mathbf{L_s} (k) - \\beta_s Here, k denotes the orientation index of the kernel, ranging from k_0 = 0, k_1 = 22.5, ... to k_7 = 157.5 degrees. For clarity, note that Grossberg and Wyse didn't just rotate the simple cell kernel by 360 degrees. Instead, they rotate two kernels, \\mathbf{L_s} and \\mathbf{R_s} , with opposite polarities by 180 degrees. This is because the kernels of the same orientation and opposite polarity will combine in the next step, making this notation more intuitive. The output of the simple cells comes from the cross-correlation between the ON-C (or OFF-C) signals, followed by half-wave rectification: \\mathbf{S^+_{s, L}} (k) = \\max(\\mathbf{K}_{s, L} (k) \\otimes \\mathbf{x}, 0) \\mathbf{S^+_{s, R}} (k) = \\max(\\mathbf{K}_{s, R} (k) \\otimes \\mathbf{x}, 0) \\mathbf{S^-_{s, L}} (k) = \\max(\\mathbf{K}_{s, L} (k) \\otimes \\bar{\\mathbf{x}}, 0) \\mathbf{S^-_{s, R}} (k) = \\max(\\mathbf{K}_{s, R} (k) \\otimes \\bar{\\mathbf{x}}, 0) Step 2b: Complex Cells : The complex cells combine the responses from simple cells of the same orientation. Be aware that the \\mathbf{C} notation here represents the response map of complex cells, not the Gaussian from Step 1. \\mathbf{C}_s (k) = F \\left[ \\mathbf{S^+_{s, L}} (k) + \\mathbf{S^+_{s, R}} (k) + \\mathbf{S^-_{s, L}} (k) + \\mathbf{S^-_{s, R}} (k) \\right] Here, F is another constant parameter. Half-wave rectification isn't necessary as the output is always non-negative. Step 2c: Hypercomplex Cells (First Competitive Stage) : This step resembles the non-max suppression in Canny edge detection as it aims to inhibit texture around boundaries that lack other collinear edges. This is accomplished by dividing the complex cells response map by the cross-correlation between the complex cell response and the oriented competition kernel \\mathbf{G_s} (k) . This kernel is normalized and positive everywhere except along the direction of the complex cell's corresponding orientation. Consequently, if there are non-collinear edges in the vicinity, the cross-correlation term in the denominator becomes large. \\mathbf{D}_{s} (k) = \\max \\left[\\frac{\\mathbf{C_s}(k)}{\\epsilon + \\mu \\sum_m (\\mathbf{C_s} (m) \\otimes \\mathbf{G_s} (k))} - \\tau, 0\\right] Step 2d: Hypercomplex Cells (Second Competitive Stage) : In this stage, only the dominant orientation is preserved (winner-takes-all) for each location on the complex cell map, \\mathbf{C_s} (k) . \\mathbf{D}_s := \\max_k \\mathbf{D}_s (k) Step 2e: Multiple Scale Interaction: Boundary Localization and Noise Suppression :","title":"The FBF Model"},{"location":"pages/segmentation-and-grouping/#configr-carpenter-gaddam-and-mingolla-2007","text":"Paper","title":"CONFIGR (Carpenter, Gaddam, and Mingolla, 2007)"},{"location":"pages/segmentation-and-grouping/#tolerance-space-theory-tst-for-gestalt-proximity-principle-peng-yang-and-li-2021","text":"Paper","title":"Tolerance Space Theory (TST) for Gestalt Proximity Principle (Peng, Yang, and Li, 2021)"},{"location":"pages/segmentation-and-grouping/#gestalt-laws-models","text":"","title":"Gestalt Laws Models"},{"location":"pages/segmentation-and-grouping/#border-ownership-models","text":"","title":"Border Ownership Models"},{"location":"pages/stimulus/","text":"VisualAlgo::Stimulus Namespace Documentation The VisualAlgo::Stimulus namespace provides functions to create stimuli in the form of 2D matrices and add noise to them. Include #include \"helpers/stimulus.hpp\" #include \"helpers/matrix.hpp\" Functions Matrix random_mondrian(int rows, int cols, int num_rectangles); The type of stimuli were used in Edwin Land's research on illuminant discounting and filling-in (1977 and 1983). Land named it McCann Mondrians, a tribute to his research partner, John McCann, and the Dutch artist Piet Mondrian (Grossberg, 2021). Creates a new Matrix object with the given number of rows and cols , and draws a specified number of random overlapping rectangles in it. Each rectangle has a random position and size, and a random value in the range [0, 1]. The size of the rectangle scales with rows and cols . Returns the new Matrix . VisualAlgo::Stimulus::Matrix matrix = random_mondrian(10, 10, 10); void add_noise(Matrix &matrix, float noise_probability); Randomly changes some percentage of pixels in the given matrix to any value in the range [0, 1]. noise_probability is the fraction of pixels that will be changed. It must be a value between 0 and 1. VisualAlgo::Stimulus::Matrix matrix = random_mondrian(10, 10, 10); add_noise(matrix, 0.1); This creates a 10x10 matrix with 10 randomly placed squares, and then adds noise to 10% of the pixels.","title":"Stimulus"},{"location":"pages/stimulus/#visualalgostimulus-namespace-documentation","text":"The VisualAlgo::Stimulus namespace provides functions to create stimuli in the form of 2D matrices and add noise to them.","title":"VisualAlgo::Stimulus Namespace Documentation"},{"location":"pages/stimulus/#include","text":"#include \"helpers/stimulus.hpp\" #include \"helpers/matrix.hpp\"","title":"Include"},{"location":"pages/stimulus/#functions","text":"Matrix random_mondrian(int rows, int cols, int num_rectangles); The type of stimuli were used in Edwin Land's research on illuminant discounting and filling-in (1977 and 1983). Land named it McCann Mondrians, a tribute to his research partner, John McCann, and the Dutch artist Piet Mondrian (Grossberg, 2021). Creates a new Matrix object with the given number of rows and cols , and draws a specified number of random overlapping rectangles in it. Each rectangle has a random position and size, and a random value in the range [0, 1]. The size of the rectangle scales with rows and cols . Returns the new Matrix . VisualAlgo::Stimulus::Matrix matrix = random_mondrian(10, 10, 10); void add_noise(Matrix &matrix, float noise_probability); Randomly changes some percentage of pixels in the given matrix to any value in the range [0, 1]. noise_probability is the fraction of pixels that will be changed. It must be a value between 0 and 1. VisualAlgo::Stimulus::Matrix matrix = random_mondrian(10, 10, 10); add_noise(matrix, 0.1); This creates a 10x10 matrix with 10 randomly placed squares, and then adds noise to 10% of the pixels.","title":"Functions"}]}